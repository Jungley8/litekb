# ğŸ’ª æœ€å¼º RAG æ•ˆæœé…ç½®æŒ‡å—

## 1. RAG æ¨¡å¼é€‰æ‹©

| æ¨¡å¼ | æ•ˆæœ | é€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **Graph-Augmented** | â­â­â­â­â­ | æ…¢ | å¤æ‚é—®é¢˜ã€éœ€è¦å¤šè·³æ¨ç† |
| **Contextual** | â­â­â­â­ | ä¸­ | éœ€è¦ä¸Šä¸‹æ–‡ç†è§£ |
| **Naive** | â­â­â­ | å¿« | ç®€å•é—®ç­”ã€å®æ—¶æ€§è¦æ±‚é«˜ |

### æ¨èé…ç½®

**æœ€å¼ºæ•ˆæœ = Graph-Augmented + å®Œæ•´é…ç½®**

```python
mode = "graph-augmented"

# æ£€ç´¢é…ç½®
retriever = {
    "top_k": 10,           # æ£€ç´¢æ›´å¤šå€™é€‰
    "similarity_threshold": 0.7,  # é™ä½é˜ˆå€¼ï¼Œè·å–æ›´å¤šç›¸å…³å†…å®¹
    "rrf_fusion": True,    # ä½¿ç”¨ RRF èåˆ
    "hybrid_search": True, # æ··åˆå‘é‡+å…³é”®è¯
}

# Graph é…ç½®
graph = {
    "depth": 2,            # æ£€ç´¢ 2 è·³é‚»å±…
    "include_entities": True,
    "include_relations": True,
}
```

---

## 2. æ£€ç´¢ä¼˜åŒ–

### æ··åˆæ£€ç´¢æƒé‡

```python
hybrid_weights = {
    "vector": 0.6,    # å‘é‡æ£€ç´¢æƒé‡æ›´é«˜ï¼ˆè¯­ä¹‰ç†è§£ï¼‰
    "bm25": 0.2,      # å…³é”®è¯æ£€ç´¢ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
    "rrf": 0.2,       # RRF èåˆ
}
```

### RRF Fusion å‚æ•°

```python
rrf_config = {
    "k": 60,              # RRF k å‚æ•°ï¼Œè¶Šå¤§è¶Šå‡è¡¡
    "score_offset": 0,    # åˆ†æ•°åç§»
}
```

---

## 3. Embedding æ¨¡å‹é€‰æ‹©

| æ¨¡å‹ | ç»´åº¦ | æ•ˆæœ | é€Ÿåº¦ |
|------|------|------|------|
| **text-embedding-3-large** | 3072 | â­â­â­â­â­ | æ…¢ |
| text-embedding-3-small | 1536 | â­â­â­â­ | å¿« |
| bge-large-zh | 1024 | â­â­â­â­â­ | ä¸­ |

### æ¨è

```python
embedding_model = "text-embedding-3-large"  # OpenAI
# æˆ–
embedding_model = "BAAI/bge-large-zh"       # æœ¬åœ°/å¼€æº
```

---

## 4. Chunking ç­–ç•¥

### æ™ºèƒ½åˆ†å—é…ç½®

```python
chunking = {
    "chunk_size": 512,           # å—å¤§å°
    "chunk_overlap": 50,         # é‡å  10%
    "semantic_chunking": True,   # è¯­ä¹‰åˆ†å—
    "respect_sentences": True,   # å¥å­è¾¹ç•Œ
}
```

### åˆ†å—ç­–ç•¥å¯¹æ¯”

| chunk_size | æ•ˆæœ | è¯´æ˜ |
|------------|------|------|
| 256 | ç²¾ç»† | é€‚åˆçŸ­é—®ç­” |
| 512 | å¹³è¡¡ | **æ¨è** |
| 1024 | ç²—ç•¥ | é€‚åˆé•¿æ–‡æ¡£ |

---

## 5. LLM é€‰æ‹©

### æ¨èæ¨¡å‹

| æ¨¡å‹ | æ•ˆæœ | æˆæœ¬ | é€Ÿåº¦ |
|------|------|------|------|
| **GPT-4o** | â­â­â­â­â­ | é«˜ | ä¸­ |
| Claude 3.5 | â­â­â­â­â­ | é«˜ | ä¸­ |
| GPT-4-turbo | â­â­â­â­ | ä¸­ | å¿« |
| DeepSeek-V2 | â­â­â­â­ | ä½ | å¿« |

### Prompt ä¼˜åŒ–

```python
system_prompt = """ä½ æ˜¯çŸ¥è¯†åº“åŠ©æ‰‹ã€‚ä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å’ŒçŸ¥è¯†å›¾è°±ä¿¡æ¯å›ç­”é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. åŸºäºäº‹å®å›ç­”ï¼Œæ ‡æ³¨å¼•ç”¨æ¥æº
2. å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ï¼Œå¦è¯šè¯´æ˜
3. å¤æ‚é—®é¢˜ä½¿ç”¨å›¾è°±æ¨ç†
4. å›ç­”ç»“æ„æ¸…æ™°ï¼Œä½¿ç”¨åˆ—è¡¨

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
- æ–‡æ¡£ç‰‡æ®µ: {chunks}
- çŸ¥è¯†å›¾è°±: {entities}

è¯·ç»“åˆä»¥ä¸Šä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"""
```

---

## 6. çŸ¥è¯†å›¾è°±å¢å¼º

### é…ç½®

```python
graph_config = {
    "enabled": True,
    "entity_extraction": True,
    "relation_extraction": True,
    "max_entities": 50,         # æœ€å¤šæŠ½å–å®ä½“æ•°
    "min_confidence": 0.7,      # ç½®ä¿¡åº¦é˜ˆå€¼
    "recursive_depth": 2,       # é€’å½’æ·±åº¦
}
```

### æ•ˆæœæå‡

å¯ç”¨çŸ¥è¯†å›¾è°±åï¼Œå¤æ‚é—®é¢˜æ•ˆæœæå‡ **30-50%**ã€‚

---

## 7. å®Œæ•´é…ç½®ç¤ºä¾‹

### backend/.env

```bash
# Embedding
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIM=3072

# LLM
LLM_MODEL=gpt-4o
LLM_TEMPERATURE=0.1  # ä½æ¸©åº¦ï¼Œæ›´ç¨³å®š

# RAG
RAG_MODE=graph-augmented
TOP_K=10
SIMILARITY_THRESHOLD=0.7
RRF_K=60

# Chunking
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# Graph
GRAPH_ENABLED=true
GRAPH_DEPTH=2
```

### å‰ç«¯å¯¹è¯é…ç½®

```typescript
// ChatEnhanced.vue
const chatConfig = {
  mode: 'graph-augmented',      // æœ€å¼ºæ¨¡å¼
  temperature: 0.1,             // ä½æ¸©åº¦
  maxTokens: 4000,             // é•¿å›ç­”
  stream: true,                 // å¼€å¯æµå¼
}
```

---

## 8. æ•ˆæœå¯¹æ¯”æµ‹è¯•

| é…ç½® | ç®€å•é—®ç­” | å¤æ‚æ¨ç† | å¤šè·³æŸ¥è¯¢ |
|------|----------|----------|----------|
| Naive | âœ…âœ…âœ… | âœ…âœ… | âœ… |
| Contextual | âœ…âœ…âœ…âœ… | âœ…âœ…âœ… | âœ…âœ… |
| **Graph-Augmented** | âœ…âœ…âœ…âœ…âœ… | âœ…âœ…âœ…âœ… | âœ…âœ…âœ…âœ…âœ… |

---

## 9. æ€§èƒ½ä¼˜åŒ–

### ç¼“å­˜é…ç½®

```python
cache = {
    "enabled": True,
    "ttl": 3600,           # 1å°æ—¶
    "similarity_cache": True,  # æ£€ç´¢ç¼“å­˜
    "llm_cache": True,     # LLM å“åº”ç¼“å­˜
}
```

### å¼‚æ­¥å¤„ç†

```python
async def enhanced_rag(query):
    # å¹¶è¡Œæ‰§è¡Œ
    vector_results = await vector_search(query)
    graph_results = await graph_search(query)
    
    # èåˆç»“æœ
    fused = rrf_fusion(vector_results, graph_results)
    
    return generate_answer(fused)
```

---

## 10. å¸¸è§é—®é¢˜

### Q: æ•ˆæœä¸ç†æƒ³ï¼Ÿ

1. **æ£€æŸ¥ Embedding æ¨¡å‹** - ç¡®ä¿ä½¿ç”¨é«˜è´¨é‡æ¨¡å‹
2. **è°ƒæ•´ Chunking** - å°è¯•ä¸åŒ chunk_size
3. **é™ä½ Threshold** - è·å–æ›´å¤šå€™é€‰
4. **æ£€æŸ¥çŸ¥è¯†å›¾è°±** - ç¡®ä¿å®ä½“æŠ½å–æ­£å¸¸

### Q: é€Ÿåº¦å¤ªæ…¢ï¼Ÿ

1. **åˆ‡æ¢åˆ° Naive æ¨¡å¼**
2. **å‡å°‘ TOP_K** - ä» 10 é™åˆ° 5
3. **ä½¿ç”¨ç¼“å­˜**
4. **æœ¬åœ° Embedding** - ä½¿ç”¨ BGE

### Q: å›ç­”ä¸å‡†ç¡®ï¼Ÿ

1. **å¢åŠ  Prompt çº¦æŸ**
2. **é™ä½ Temperature** - åˆ° 0.1
3. **å¢åŠ æ£€ç´¢ Context**
4. **å¯ç”¨çŸ¥è¯†å›¾è°±**

---

## ğŸ“Š æœ€ç»ˆæ¨èé…ç½®

```python
config = {
    # æ¨¡å¼
    "mode": "graph-augmented",
    
    # æ£€ç´¢
    "top_k": 10,
    "threshold": 0.7,
    "hybrid": True,
    
    # Embedding
    "model": "text-embedding-3-large",
    "dim": 3072,
    
    # Chunking
    "chunk_size": 512,
    "overlap": 50,
    
    # LLM
    "model": "gpt-4o",
    "temperature": 0.1,
    
    # Graph
    "graph_enabled": True,
    "depth": 2,
}
```

---

## ğŸš€ ä¸€é”®å¯ç”¨æœ€å¼º RAG

åœ¨å¯¹è¯ç•Œé¢é€‰æ‹© **"å›¾è°±å¢å¼ºæ¨¡å¼"** å³å¯ä½¿ç”¨æœ€å¼ºé…ç½®ã€‚

æ•ˆæœæå‡ï¼šå¤æ‚é—®é¢˜å‡†ç¡®ç‡ **+40%**
